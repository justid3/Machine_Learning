{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/justindavis/Documents/Python/ml_for_nfl_master/notebooks',\n",
       " '/Users/justindavis/anaconda3/lib/python37.zip',\n",
       " '/Users/justindavis/anaconda3/lib/python3.7',\n",
       " '/Users/justindavis/anaconda3/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/Users/justindavis/anaconda3/lib/python3.7/site-packages',\n",
       " '/Users/justindavis/anaconda3/lib/python3.7/site-packages/aeosa',\n",
       " '/Users/justindavis/anaconda3/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/Users/justindavis/.ipython',\n",
       " '/Users/justindavis/Documents/Python/ml_for_nfl_master',\n",
       " '/Users/justindavis/Documents/Python/ml_for_nfl_master',\n",
       " '/Users/justindavis/Documents/Python/ml_for_nfl_master/src/data']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/justindavis/Documents/Python/ml_for_nfl_master')\n",
    "sys.path.append('/Users/justindavis/Documents/Python/ml_for_nfl_master/src/data')\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NoSectionError",
     "evalue": "No section: 'psql database'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSectionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ffa0c7f318cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0myear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'2017'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# loading df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mdb_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpsql_operations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPostgresConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mrbDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_db_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT * FROM rbs_v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mqbDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_db_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT * FROM qbs_v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Python/ml_for_nfl_master/src/data/psql_operations.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/Users/justindavis/Document/ml_for_nfl_master/src/data/config.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'psql database'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'host'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'psql database'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'db_name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'psql database'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/configparser.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, section, option, raw, vars, fallback)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \"\"\"\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unify_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNoSectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_UNSET\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/configparser.py\u001b[0m in \u001b[0;36m_unify_values\u001b[0;34m(self, section, vars)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msection\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_section\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNoSectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0;31m# Update with the entry specific variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0mvardict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSectionError\u001b[0m: No section: 'psql database'"
     ]
    }
   ],
   "source": [
    "from src.data import make_dataset\n",
    "from src.data import psql_operations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tpot.builtins import ZeroCount\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tpot.builtins import StackingEstimator\n",
    "import configparser\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weeks = [str(x) for x in range(1, 17)]\n",
    "year = '2017'\n",
    "# loading df\n",
    "db_connection = psql_operations.PostgresConnection()\n",
    "rbDf = db_connection.get_db_data('SELECT * FROM rbs_v2')\n",
    "qbDf = db_connection.get_db_data('SELECT * FROM qbs_v2')\n",
    "# setting columns that duplicate QB columns in the RB data to zero to allow for data cleaning\n",
    "for col in ['score_for', 'score_against', 'win_loss']:\n",
    "    rbDf[col] = 0\n",
    "cleaner = make_dataset.DataCleaner()\n",
    "print('Initially cleaning and aggregating the RB data')\n",
    "aggRbDf = cleaner.clean_data(rbDf, 'rbs_v2')\n",
    "\n",
    "print('Initially cleaning and aggregating the QB data')\n",
    "aggQbDf = cleaner.clean_data(qbDf, 'qbs_v2')\n",
    "\n",
    "print('getting maps and stuff from the DB')\n",
    "winnings_list = []\n",
    "vegas_winnings_list = []\n",
    "accuracy_list = []\n",
    "vegas_accuracy_list = []\n",
    "for week in weeks:\n",
    "    print(f'calculating week {week}...')\n",
    "\n",
    "    trainRb_Qb = pd.merge(aggQbDf, aggRbDf, on='game_id', suffixes=('_qb', '_rb')).sort_values('total_touches_rb')\n",
    "    trainRb_Qb = trainRb_Qb.drop_duplicates(subset='game_id')\n",
    "    testing_data = cleaner.get_testing_data(aggRbDf, aggQbDf, week, year)\n",
    "    trainRb_Qb = trainRb_Qb.drop('game_id', 1)\n",
    "\n",
    "    training_features = trainRb_Qb.drop('win_loss', axis=1).values\n",
    "    training_target = trainRb_Qb['win_loss'].values\n",
    "    prediction_features = testing_data.drop('win_loss', axis=1).values\n",
    "\n",
    "    # Score on the training set was:0.6203702298990865\n",
    "    pipeline = make_pipeline(RFE(estimator=ExtraTreesClassifier(criterion=\"entropy\", max_features=0.6500000000000001, n_estimators=100), step=0.9500000000000001),\n",
    "    StackingEstimator(estimator=DecisionTreeClassifier(criterion=\"entropy\", max_depth=3, min_samples_leaf=15, min_samples_split=18)),\n",
    "    KNeighborsClassifier(n_neighbors=68, p=1, weights=\"distance\"))\n",
    "\n",
    "    pipeline.fit(training_features, training_target)\n",
    "    # 1 as a prediction means the home team won\n",
    "    predictions = pipeline.predict(prediction_features)\n",
    "    confidences = pipeline.predict_proba(prediction_features)\n",
    "\n",
    "    id_to_short_team = {team_id: team for team_id, team in zip(cleaner.team_map['team_id'], cleaner.team_map['team'])}\n",
    "\n",
    "    # include confidence scores in this zip\n",
    "    halfway_index = int(len(predictions)/2)\n",
    "    \n",
    "    # predictions\n",
    "    round_1_predictions = []\n",
    "    round_2_predictions = []\n",
    "    current_index = 0\n",
    "    for home_team_id, away_team_id, prediction in zip(list(testing_data['team_id_qb']), list(testing_data['team_id_away_qb']), predictions):\n",
    "        home = id_to_short_team[home_team_id].upper()\n",
    "        away = id_to_short_team[away_team_id].upper()\n",
    "        # avoiding 2 loops, so switch rounds lives here:\n",
    "        if current_index < halfway_index:\n",
    "            # round 1\n",
    "            if prediction == 1:\n",
    "                round_1_predictions.append(home)\n",
    "            else:\n",
    "                round_1_predictions.append(away)\n",
    "        else:\n",
    "            if prediction == 1:\n",
    "                round_2_predictions.append(home)\n",
    "            else:\n",
    "                round_2_predictions.append(away)\n",
    "        current_index += 1\n",
    "\n",
    "    winning_team_predictions = []\n",
    "    winning_team_confidences = []\n",
    "    for round1_conf, round2_conf, round1, round2 in zip(confidences[:halfway_index], confidences[halfway_index:], round_1_predictions, round_2_predictions):\n",
    "        round1_conf = max(round1_conf)\n",
    "        round2_conf = max(round2_conf)\n",
    "        # both rounds of prediction agree, take the average of the confidences\n",
    "        if round1 == round2:\n",
    "            winning_team_predictions.append(round1)\n",
    "            winning_team_confidences.append(np.average([round1_conf, round2_conf]))\n",
    "        # rounds of prediction don't agree, therefore take the difference of the confidences\n",
    "        else:\n",
    "            if round1_conf > round2_conf:\n",
    "                winning_team_predictions.append(round1)\n",
    "                winning_team_confidences.append(round1_conf - round2_conf)\n",
    "            else:\n",
    "                winning_team_predictions.append(round2)\n",
    "                winning_team_confidences.append(round2_conf - round1_conf)\n",
    "\n",
    "    results_df = db_connection.get_db_data(f'SELECT winner FROM results WHERE week={week}')\n",
    "    team_to_abbr = {\n",
    "        'raiders': 'oak',\n",
    "        'patriots': 'ne',\n",
    "        'bills': 'buf',\n",
    "        'texans': 'hou',\n",
    "        'saints': 'no',\n",
    "        'panthers': 'car',\n",
    "        'bengals': 'cin',\n",
    "        'browns': 'cle',\n",
    "        'packers': 'gb',\n",
    "        'lions': 'det',\n",
    "        'seahawks': 'sea',\n",
    "        'jaguars': 'jax',\n",
    "        'jets': 'nyj',\n",
    "        'chiefs': 'kc',\n",
    "        'broncos': 'den',\n",
    "        'dolphins': 'mia',\n",
    "        'buccaneers': 'tb',\n",
    "        'vikings': 'min',\n",
    "        'cardinals': 'ari',\n",
    "        'giants': 'nyg',\n",
    "        'titans': 'ten',\n",
    "        'steelers': 'pit',\n",
    "        'colts': 'ind',\n",
    "        'ravens': 'bal',\n",
    "        'cowboys': 'dal',\n",
    "        'chargers': 'lac',\n",
    "        'rams': 'lar',\n",
    "        '49ers': 'sf',\n",
    "        'bears': 'chi',\n",
    "        'redskins': 'wsh',\n",
    "        'eagles': 'phi',\n",
    "        'falcons': 'atl'\n",
    "    }\n",
    "\n",
    "    print('assessing accuracy of the predictions')\n",
    "    results = [team_to_abbr[long_team].upper() for long_team in list(results_df['winner'].values)]\n",
    "    correct_predictions = []\n",
    "    for team in winning_team_predictions:\n",
    "        correct = True\n",
    "        if team not in results: correct = False\n",
    "        correct_predictions.append(correct)\n",
    "\n",
    "    percent_money_allocation = [x/sum(winning_team_confidences) for x in winning_team_confidences]\n",
    "    vegas_percent_money_allocation = [1/len(winning_team_confidences)] * len(winning_team_confidences)\n",
    "\n",
    "    odds_df = db_connection.get_db_data('SELECT * FROM \\\"2017_odds\\\" WHERE week=' + week)\n",
    "    \n",
    "    correct_vegas_predictions = []\n",
    "    for team in list(odds_df['favoriteteam'].values):\n",
    "        correct = True\n",
    "        if team not in results: correct = False\n",
    "        correct_vegas_predictions.append(correct)\n",
    "    \n",
    "    # calculating model winnings\n",
    "    total_winnings = 0\n",
    "    for correct, stake, predicted_team in zip(correct_predictions, percent_money_allocation, winning_team_predictions):\n",
    "        fav_team = ''\n",
    "        fav_odds = ''\n",
    "        und_odds = ''\n",
    "        winnings = 0\n",
    "        stake *= 1000\n",
    "        for i, row in odds_df.iterrows():\n",
    "            if predicted_team in list(row):\n",
    "                fav_team = row['favoriteteam']\n",
    "                fav_odds = row['favorite']\n",
    "                und_odds = row['underdog']\n",
    "\n",
    "        if correct and predicted_team == fav_team:\n",
    "            winnings = stake / (fav_odds / 100) + stake\n",
    "        elif correct and predicted_team != fav_team:\n",
    "            winnings = stake * (und_odds / 100) + stake\n",
    "        else:\n",
    "            winnings = 0\n",
    "            \n",
    "        total_winnings += winnings\n",
    "        \n",
    "    # calculating vegas winnings\n",
    "    total_vegas_winnings = 0\n",
    "    for correct, stake, predicted_team in zip(correct_vegas_predictions, vegas_percent_money_allocation, list(odds_df.loc[:, 'favoriteteam'])):\n",
    "        fav_team = ''\n",
    "        fav_odds = ''\n",
    "        und_odds = ''\n",
    "        winnings = 0\n",
    "        stake *= 1000\n",
    "        for i, row in odds_df.iterrows():\n",
    "            if predicted_team in list(row):\n",
    "                fav_team = row['favoriteteam']\n",
    "                fav_odds = row['favorite']\n",
    "                und_odds = row['underdog']\n",
    "\n",
    "        if correct and predicted_team == fav_team:\n",
    "            winnings = stake / (fav_odds / 100) + stake\n",
    "        elif correct and predicted_team != fav_team:\n",
    "            winnings = stake * (und_odds / 100) + stake\n",
    "        else:\n",
    "            winnings = 0\n",
    "\n",
    "        total_vegas_winnings += winnings\n",
    "        \n",
    "    total_prediction_accuracy = np.average(correct_predictions)\n",
    "    total_vegas_prediction_accuracy = np.average(correct_vegas_predictions)\n",
    "    \n",
    "    winnings_list.append(total_winnings)\n",
    "    vegas_winnings_list.append(total_vegas_winnings)\n",
    "    accuracy_list.append(total_prediction_accuracy)\n",
    "    vegas_accuracy_list.append(total_vegas_prediction_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating vegas favorite betting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Create a dataset\n",
    "graph_titles=['Accuracy Per Week', 'Model Rolling Average Return']\n",
    "df = pd.DataFrame({\n",
    "    \"Titles\": np.repeat(graph_titles, 16),\n",
    "    \"Week\": list(range(1, 17)) * 2,\n",
    "    \"Accuracy\": np.array(winnings_per_week + percent_winnings_rolling_average)\n",
    "})\n",
    " \n",
    "g = sns.FacetGrid(df, col='Titles', hue='Titles', size=5)\n",
    "plt.xlabel('Week', size=14)\n",
    "g = g.map(plt.grid, alpha=0.2)\n",
    "g = g.map(plt.plot, 'Week', 'Return')\n",
    "g = g.map(plt.fill_between, 'Week', 'Return', alpha=0.2)\n",
    "g = g.set_xlabels('Week', size=14)\n",
    "g = g.set_ylabels('Return (%)', size=14)\n",
    "g = g.set_titles(\"{col_name}\", size=14)\n",
    "[plt.setp(ax.get_xticklabels(), size=12) for ax in g.axes.flat]\n",
    "[plt.setp(ax.get_yticklabels(), size=12) for ax in g.axes.flat]\n",
    "\n",
    "plt.subplots_adjust(top=0.80)\n",
    "g = g.fig.suptitle('Model Return by Week', size=20)\n",
    "\n",
    "plt.xticks(range(1,17), range(1,17))\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.savefig('2017_winnings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "weeks = [x for x in range(1, 17)]\n",
    "original_weeks = [x for x in range(0, 16)]\n",
    "mpl.style.use('seaborn')\n",
    "plt.figure(figsize=(12,8))\n",
    "pal = sns.color_palette(\"Set1\")\n",
    "\n",
    "plt.plot(accuracy_list, label='ML Model Accuracy')\n",
    "plt.plot(vegas_accuracy_list, label='Vegas Accuracy')\n",
    "plt.ylabel('Accuracy', size=14)\n",
    "plt.xlabel('Week', size=14)\n",
    "plt.title('Accuracy Comparison over 2017 Season', size=20)\n",
    "plt.xticks(original_weeks, weeks, size=12)\n",
    "plt.yticks(size=12)\n",
    "plt.legend()\n",
    "plt.savefig('2017_accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "percent_winnings_rolling_average = []\n",
    "vegas_percent_winnings_rolling_average = []\n",
    "for i, total_bet in enumerate(range(1000, 17000, 1000)):\n",
    "    percent_winnings_rolling_average.append((sum(winnings_list[:i+1]) - total_bet)/total_bet)\n",
    "    vegas_percent_winnings_rolling_average.append((sum(vegas_winnings_list[:i+1]) - total_bet)/total_bet)\n",
    "winnings_per_week = [(x - 1000)/1000 for x in winnings_list]\n",
    "vegas_winnings_per_week = [(x - 1000)/1000 for x in vegas_winnings_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_df = pd.concat([homeDf[homeDf['game_id'] == 'NE_BUF'], homeDf[homeDf['game_id'] == 'PHI_OAK']])\n",
    "print(pipeline.predict_proba(sb_df.drop(['win_loss', 'game_id', 'index_qb','index_rb'], 1).values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'% Return Per Week': [x * 100 for x in winnings_per_week + vegas_winnings_per_week],\n",
    "          'Rolling Average % Return': [x * 100 for x in percent_winnings_rolling_average + vegas_percent_winnings_rolling_average],\n",
    "          '% Accuracy': [x * 100 for x in accuracy_list + vegas_accuracy_list],\n",
    "          'Predictor': np.repeat(['ML Model', 'Vegas'], 16),\n",
    "          'Week': list(range(1, 17)) * 2}\n",
    "pairplot = pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "g = sns.PairGrid(pairplot, y_vars=['% Accuracy', '% Return Per Week', 'Rolling Average % Return'], x_vars='Week', hue='Predictor', size=5, aspect=3)\n",
    "g = g.map(plt.plot)\n",
    "g = g.map(plt.fill_between, alpha=0.2)\n",
    "g = g.add_legend()\n",
    "for ax in g.axes.flat:\n",
    "    _ = plt.setp(ax.get_xticklabels(), visible=True)\n",
    "    ax.set_xlim(1,16)\n",
    "plt.savefig('2017_all_results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.axes_style()\n",
    "sns.set_style({\"xtick.major.size\": 12,\n",
    "              'ytick.major.size': 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot.index.name = 'Week'\n",
    "pairplot[['Rolling Average % Return']][:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot.index = [x - 1 for x in pairplot.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6566158 - 0.51805785 + .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "open(\"src/data/config.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“localhost”\n",
      "“nfldata”\n",
      "“”\n",
      "“”\n",
      "“5432”\n"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(r'/Users/justindavis/Documents/Python/ml_for_nfl_master/src/data/config.txt')\n",
    "host = config.get('psql database', 'host')\n",
    "db_name = config.get('psql database', 'db_name')\n",
    "user = config.get('psql database', 'user')\n",
    "password = config.get('psql database', 'password')\n",
    "port = config.get('psql database', 'port')\n",
    "print(host)\n",
    "print(db_name)\n",
    "print(user)\n",
    "print(password)\n",
    "print(port)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
